{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import rename, times\n",
    "# from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        contest_id     q_rating  contest_type  question_no     accuracy  \\\n",
      "count  4700.000000  4700.000000   4700.000000  4700.000000  4700.000000   \n",
      "mean   1102.369149  1891.595745      2.234894     3.822340     0.634800   \n",
      "std     251.454666   677.331562      1.077807     2.253873     0.258493   \n",
      "min     641.000000   800.000000      0.000000     1.000000     0.002401   \n",
      "25%     886.000000  1400.000000      2.000000     2.000000     0.457588   \n",
      "50%    1103.500000  1900.000000      2.000000     4.000000     0.678199   \n",
      "75%    1322.000000  2400.000000      3.000000     5.000000     0.853926   \n",
      "max    1529.000000  3500.000000      4.000000    16.000000     1.000000   \n",
      "\n",
      "       avg_solving_time    sub_ratio  tried_but_cannot_solved  \\\n",
      "count       4700.000000  4700.000000              4700.000000   \n",
      "mean        2451.258099     0.327319               446.673830   \n",
      "std         1302.181881     0.330178               694.320172   \n",
      "min            9.000000     0.000070                 0.000000   \n",
      "25%         1661.950253     0.023744                31.000000   \n",
      "50%         2318.044763     0.200000               155.500000   \n",
      "75%         2986.712085     0.620719               581.000000   \n",
      "max        17935.148148     1.000000              7112.000000   \n",
      "\n",
      "       total_participant  total_correct_sub_for_each_q  total_sub_for_each_q  \\\n",
      "count        4700.000000                   4700.000000           4700.000000   \n",
      "mean         4878.868936                   1529.629574           1976.303404   \n",
      "std          4295.019058                   2487.934386           2875.007369   \n",
      "min            18.000000                      1.000000              1.000000   \n",
      "25%          1015.000000                     49.000000            110.000000   \n",
      "50%          4022.000000                    377.000000            585.500000   \n",
      "75%          6544.750000                   2076.500000           2973.250000   \n",
      "max         19332.000000                  16217.000000          16747.000000   \n",
      "\n",
      "       total_time_to_sove_q  \n",
      "count          4.700000e+03  \n",
      "mean           2.505433e+06  \n",
      "std            3.628160e+06  \n",
      "min            9.000000e+00  \n",
      "25%            1.293932e+05  \n",
      "50%            8.312790e+05  \n",
      "75%            3.606592e+06  \n",
      "max            2.817065e+07  \n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "df = pd.read_csv('merged-1-to-16.csv')\n",
    "#remove data of unrated round like technocup etc.....\n",
    "# df=df.reset_index()\n",
    "# print(df.head())\n",
    "# droping all row having any negative value in column\n",
    "df = df[df.select_dtypes(include=[np.number]).ge(0).all(1)]\n",
    "# droping row having avg solving time is gratar than 10 hr and less than equal to 0\n",
    "df = df.loc[(df['avg_solving_time'] <= 18000) & (df['avg_solving_time'] > 0)]\n",
    "df_div0 = df.loc[(df['contest_type'] == 0)]\n",
    "df_div1 = df.loc[(df['contest_type'] == 1)]\n",
    "df_div2 = df.loc[(df['contest_type'] == 2)]\n",
    "df_div3 = df.loc[(df['contest_type'] == 3)]\n",
    "# df_div3.describe()\n",
    "# df.head()\n",
    "# df.describe()\n",
    "# print(df.head())\n",
    "print(df.describe())\n",
    "q_1 = df.loc[:, ['question_no', 'q_rating', 'contest_type']]\n",
    "q_1 = q_1.loc[(q_1['question_no'] == 1) & (q_1['contest_type'] == 1)]\n",
    "# print(q_1)\n",
    "# print(q_1.describe())\n",
    "x = df.drop(['q_rating'], axis=1)\n",
    "x = x.drop(['contest_id'], axis=1)\n",
    "y = df['q_rating']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custum code for extracting data of sigle constes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  contest_id contest_type question_no  accuracy  avg_solving_time  sub_ratio  \\\n",
      "0       1586            1           1  0.934360       1364.093558   0.900870   \n",
      "1       1586            1           2  0.860317       1452.897657   0.627175   \n",
      "2       1586            1           3  0.585795       2231.899678   0.279544   \n",
      "3       1586            1           4  0.923506       2498.935913   0.248050   \n",
      "4       1586            1           5  0.864122       2062.607774   0.084883   \n",
      "5       1586            1           6  0.725857       2049.339056   0.034943   \n",
      "6       1586            1           7  0.692308       2633.074074   0.004049   \n",
      "7       1586            1           8  0.642857       3263.888889   0.001350   \n",
      "8       1586            1           9  0.083333       2515.000000   0.000150   \n",
      "\n",
      "  tried_but_cannot_solved total_participant total_correct_sub_for_each_q  \\\n",
      "0                     422              6668                         6007   \n",
      "1                     679              6668                         4182   \n",
      "2                    1318              6668                         1864   \n",
      "3                     137              6668                         1654   \n",
      "4                      89              6668                          566   \n",
      "5                      88              6668                          233   \n",
      "6                      12              6668                           27   \n",
      "7                       5              6668                            9   \n",
      "8                      11              6668                            1   \n",
      "\n",
      "  total_sub_for_each_q total_time_to_sove_q  \n",
      "0                 6429              8194110  \n",
      "1                 4861              6076018  \n",
      "2                 3182              4160261  \n",
      "3                 1791              4133240  \n",
      "4                  655              1167436  \n",
      "5                  321               477496  \n",
      "6                   39                71093  \n",
      "7                   14                29375  \n",
      "8                   12                 2515  \n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=['contest_id', 'q_rating', 'contest_type', 'question_no', 'accuracy',\n",
    "                             'avg_solving_time', 'sub_ratio', 'tried_but_cannot_solved', 'total_participant',\n",
    "                             'total_correct_sub_for_each_q', 'total_sub_for_each_q', 'total_time_to_sove_q'])\n",
    "#sub_ratio=correct sub/total participnat\n",
    "#accuracy=correct sub/total sub\n",
<<<<<<< HEAD
    "#avg sol time=sum of time of accepted sol/no of accepted sol\n",
    "id = \"1586\"\n",
=======
    "#avg sol time=sum of time of accepted sol/no of accepted \n",
>>>>>>> d7599faaeaa26c5f66e02949ac8c2a46e9a0cc7d
    "# print(cnt,id)\n",
    "# id=\"1526\"\n",
    "standing = requests.get(\n",
    "    \"https://codeforces.com/api/contest.standings?contestId=\"+id)\n",
    "\n",
    "# print(standing.json()\n",
    "json_file = standing.json()\n",
    "re = json_file['result']['rows']\n",
    "contest_name = json_file['result']['contest']['name']\n",
    "# useful data\n",
    "total_participant = len(re)\n",
    "total_correct_sub_for_each_question = {}\n",
    "problem_rating = {}\n",
    "tried_but_not_solved = {}\n",
    "total_time_to_solve_q = {}\n",
    "total_sub_for_each_question = {}\n",
    "avg_solve_time_for_each_question = {}\n",
    "total_no_of_question = 0\n",
    "accuracy = {}\n",
    "\n",
    "q_list = json_file['result']['problems']\n",
    "for i in q_list:\n",
    "  # print(i['index'],i['rating'])\n",
    "  if 'rating' in i:\n",
    "    problem_rating[total_no_of_question+1] = i['rating']\n",
    "  else:\n",
    "    problem_rating[total_no_of_question+1] = -1\n",
    "  total_no_of_question += 1\n",
    "  total_time_to_solve_q[total_no_of_question] = 0\n",
    "  total_correct_sub_for_each_question[total_no_of_question] = 0\n",
    "  tried_but_not_solved[total_no_of_question] = 0\n",
    "  total_sub_for_each_question[total_no_of_question] = 0\n",
    "  accuracy[total_no_of_question] = 0\n",
    "# print(problem_rating)\n",
    "# print(total_no_of_question)\n",
    "# print(re)\n",
    "for i in re:\n",
    "  user_sub_for_each_q = i['problemResults']\n",
    "  question_id = 1\n",
    "  temp = []\n",
    "  for i in user_sub_for_each_q:\n",
    "    if('bestSubmissionTimeSeconds' in i):\n",
    "      temp.append([i['bestSubmissionTimeSeconds'], question_id])\n",
    "      total_correct_sub_for_each_question[question_id] += 1\n",
    "    else:\n",
    "      temp.append([0, question_id])\n",
    "      if i['rejectedAttemptCount'] > 0:\n",
    "        tried_but_not_solved[question_id] += 1\n",
    "    question_id += 1\n",
    "  temp.sort()\n",
    "  prev_time = 0\n",
    "  for [x, y] in temp:\n",
    "    total_time_to_solve_q[y] += x-prev_time\n",
    "    prev_time = x\n",
    "  # print(total_time_to_solve_q)\n",
    "for i in range(total_no_of_question):\n",
    "  total_sub_for_each_question[i +\n",
    "                              1] = total_correct_sub_for_each_question[i+1]+tried_but_not_solved[i+1]\n",
    "  if total_sub_for_each_question[i+1] > 0:\n",
    "    accuracy[i+1] = total_correct_sub_for_each_question[i+1] / \\\n",
    "        total_sub_for_each_question[i+1]\n",
    "\n",
    "#output\n",
    "# print(total_participant)\n",
    "# print(total_correct_sub_for_each_question)\n",
    "# print(total_sub_for_each_question)\n",
    "# print(tried_but_not_solved)\n",
    "# print(total_time_to_solve_q)\n",
    "# print(\"avg solving time in second\")\n",
    "for i in range(total_no_of_question):\n",
    "  if(total_correct_sub_for_each_question[i+1] > 0):\n",
    "    avg_solve_time_for_each_question[i+1] = total_time_to_solve_q[i+1] / \\\n",
    "        total_correct_sub_for_each_question[i+1]\n",
    "  else:\n",
    "    avg_solve_time_for_each_question[i+1] = 0\n",
    "# print(avg_solve_time_for_each_question)\n",
    "contest_type = 4  # for all other contest\n",
    "if \"Div. 3\" in contest_name:\n",
    "  contest_type = 3\n",
    "if \"Div. 2\" in contest_name:\n",
    "  contest_type = 2\n",
    "if \"Div. 1\" in contest_name:\n",
    "  contest_type = 1\n",
    "if \"Global Round\" in contest_name:\n",
    "  contest_type = 0\n",
    "for i in range(total_no_of_question):\n",
    "  data = data.append({'contest_id': id, 'q_rating': problem_rating[i+1], 'contest_type': contest_type, 'question_no': i+1, 'accuracy': accuracy[i+1],\n",
    "                      'avg_solving_time': avg_solve_time_for_each_question[i+1], 'sub_ratio': total_correct_sub_for_each_question[i+1]/total_participant,\n",
    "                      'tried_but_cannot_solved': tried_but_not_solved[i+1], 'total_participant': total_participant, 'total_correct_sub_for_each_q':\n",
    "                      total_correct_sub_for_each_question[i+1], 'total_sub_for_each_q': total_sub_for_each_question[i+1], 'total_time_to_sove_q':\n",
    "                      total_time_to_solve_q[i+1]}, ignore_index=True)\n",
    "# print(data)\n",
    "data = data.drop(['q_rating'], axis=1)\n",
    "print(data)\n",
    "data.to_csv('contest1586.csv',index=False)\n",
    "# print(taken)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output for global rounds div 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 875., 1284., 1693., 1777., 2198., 2576., 3100., 3238., 3460.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_div0=df_div0.drop(['q_rating'],axis=1)\n",
    "# x_div1=x_div1.drop(['contest_id'],axis=1)\n",
    "y_div0=df_div0['q_rating']\n",
    "# print(x_div1.head())\n",
    "# print(y_div1.head())\n",
    "div0_model=RandomForestRegressor()\n",
    "train_x_forest_div0,test_x_forest_div0,train_y_forest_div0,test_y_forest_div0=train_test_split(x_div0,y_div0,test_size=0.2,random_state=42)\n",
    "div0_model.fit(train_x_forest_div0,train_y_forest_div0)\n",
    "# print(test_x_forest_div1.head())\n",
    "y_predict_forest_div0=div0_model.predict(test_x_forest_div0)\n",
    "# test_x_forest_div11=[[1,5,0.056\t,4440,0.00709219858,22,1,23]]\n",
    "y_predict=div0_model.predict(data)\n",
    "# print(y_predict_forest_div11)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output for div 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 877., 1273., 1688., 1823., 2330., 2480., 3038., 3266., 3421.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_div1=df_div1.drop(['q_rating'],axis=1)\n",
    "# x_div1=x_div1.drop(['contest_id'],axis=1)\n",
    "y_div1=df_div1['q_rating']\n",
    "# print(x_div1.head())\n",
    "# print(y_div1.head())\n",
    "div1_model=RandomForestRegressor()\n",
    "train_x_forest_div1,test_x_forest_div1,train_y_forest_div1,test_y_forest_div1=train_test_split(x_div1,y_div1,test_size=0.2,random_state=42)\n",
    "div1_model.fit(train_x_forest_div1,train_y_forest_div1)\n",
    "# print(test_x_forest_div1.head())\n",
    "y_predict_forest_div1=div1_model.predict(test_x_forest_div1)\n",
    "# test_x_forest_div11=[[1,5,0.056\t,4440,0.00709219858,22,1,23]]\n",
    "y_predict=div1_model.predict(data)\n",
    "# print(y_predict_forest_div11)\n",
    "y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output for div 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 815., 1027., 1516., 1618., 1936., 2095., 2563., 2644., 2900.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_div2 = df_div2.drop(['q_rating'], axis=1)\n",
    "# x_div2=x_div2.drop(['contest_id'],axis=1)\n",
    "y_div2 = df_div2['q_rating']\n",
    "div2_model = RandomForestRegressor()\n",
    "train_x_forest_div2, test_x_forest_div2, train_y_forest_div2, test_y_forest_div2 = train_test_split(\n",
    "    x_div2, y_div2, test_size=0.05, random_state=42)\n",
    "# print(train_x_forest_div2.describe())\n",
<<<<<<< HEAD
    "div2_model.fit(train_x_forest_div2, train_y_forest_div2)\n",
    "y_predict_forest_div2 = div2_model.predict(test_x_forest_div2)\n",
=======
    "model.fit(train_x_forest_div2, train_y_forest_div2)\n",
    "# y_predict_forest_div2 = model.predict(test_x_forest_div2)\n",
>>>>>>> d7599faaeaa26c5f66e02949ac8c2a46e9a0cc7d
    "# y_predict\n",
    "y_predict_forest_div2 = div2_model.predict(data)\n",
    "y_predict_forest_div2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output for div 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 800., 1038., 1434., 1476., 1712., 1827., 2169., 2378., 2512.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_div3 = df_div3.drop(['q_rating'], axis=1)\n",
    "# x_div2=x_div2.drop(['contest_id'],axis=1)\n",
    "y_div3 = df_div3['q_rating']\n",
    "# print(y_div3)\n",
    "div3_model = RandomForestRegressor()\n",
    "train_x_forest_div3, test_x_forest_div3, train_y_forest_div3, test_y_forest_div3 = train_test_split(\n",
    "    x_div3, y_div3, test_size=0.2, random_state=42)\n",
    "div3_model.fit(train_x_forest_div3, train_y_forest_div3)\n",
    "y_predict_forest_div3 = div3_model.predict(data)\n",
    "# y_predict\n",
    "y_predict_forest_div3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating flask app of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 875., 1284., 1693., 1777., 2198., 2576., 3100., 3238., 3460.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename ='div0_model.sav'\n",
    "pickle.dump(div0_model,open(filename,'wb'))\n",
    "load_model=pickle.load(open(filename,'rb'))\n",
    "output=load_model.predict(data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 877., 1273., 1688., 1823., 2330., 2480., 3038., 3266., 3421.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename ='div1_model.sav'\n",
    "pickle.dump(div1_model,open(filename,'wb'))\n",
    "load_model=pickle.load(open(filename,'rb'))\n",
    "output=load_model.predict(data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 815., 1027., 1516., 1618., 1936., 2095., 2563., 2644., 2900.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename ='div2_model.sav'\n",
    "pickle.dump(div2_model,open(filename,'wb'))\n",
    "load_model=pickle.load(open(filename,'rb'))\n",
    "output=load_model.predict(data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 800., 1038., 1434., 1476., 1712., 1827., 2169., 2378., 2512.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "filename ='div3_model.sav'\n",
    "pickle.dump(div3_model,open(filename,'wb'))\n",
    "load_model=pickle.load(open(filename,'rb'))\n",
    "output=load_model.predict(data)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fb7de5e7d60a9982dc76edf1c321b7b73ad9b771ff0939a5a6d2357aea103d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
